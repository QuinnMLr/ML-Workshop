{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\"> Nationwide Sponsored Data Science Workshop </h1>\n",
    "\n",
    "\n",
    "A github repository containing the dataset, data dictionary, notebook, and scripts for installing all required dependencies can be found [here](https://github.com/QuinnMLr/Nationwide-ML-Workshop) \n",
    "\n",
    "In this workshop, we will be helping a hypothetical insurance company, ACME Insurance, figure out what drives customer satisfaction using data obtained in a customer survey ___(NOTE: THIS IS NOT REAL DATA)___.  Understanding how various factors such as age, region, and premium changes influence customer satisfaction helps companies like ACME make informed decisions that may increase satisfaction, and hence retain more customers.\n",
    "\n",
    "This is beginner-intermediate level and does not assume any prior data science experience \n",
    "\n",
    "The notebook demonstrates the following fundamental data science concepts:\n",
    "- Loading data into a notebook\n",
    "- Handling duplicate data\n",
    "- Handling null values\n",
    "- Mapping variable values\n",
    "- Converting data types\n",
    "- Visualizing distributions\n",
    "- Visualizing correlations \n",
    "- Handling date-time data\n",
    "- Creating dummy variables\n",
    "- Splitting data into test and training sets\n",
    "- Creating a regression model\n",
    "- Creating a random forest \n",
    "- Comparing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___We'll begin with importing the libraries we'll use throughout the notebook and configure some display settings.  Then, we'll load in the data, glimpse it, view the metadata, and look for missing values.___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries used throughout notebook\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tell pandas to display only 3 decimals in tables\n",
    "pd.options.display.float_format = '{:,.8f}'.format\n",
    "\n",
    "#Show all columns with head()\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#Read in dataset\n",
    "data_path = 'ACME_SURVEY.csv'\n",
    "acme = pd.read_csv(data_path)\n",
    "\n",
    "#Glimpse data\n",
    "acme.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View metadata\n",
    "acme.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View missing values\n",
    "acme.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Let's decide how we're going to leverage our data to answer the question 'What drives customer satisfaction?'  Notice 'Q1' to 'Q6' are some form of satisfaction rating on a 10-point scale?  Let's see if these ratings are correlated___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "#Take columns 'Q1' to 'Q6'\n",
    "acme_q = acme.loc[:, 'Q1':'Q6']\n",
    "\n",
    "#Drop NaN's\n",
    "acme_q3 = acme_q.dropna()\n",
    "\n",
    "#Create correlation matrix\n",
    "corr = acme_q3.corr()\n",
    "\n",
    "#Create correlation matrix heatmap\n",
    "sns.heatmap(corr, cmap =\"YlGnBu\", annot = True,vmin = 0,vmax = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Looks like there is strong correlation.  Because these variables are strongly correlated, and there're quite a bit of missing values, we'll take the average of the ratings to be our response variable___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create average satisfaction variable\n",
    "acme['SAT_AVE'] = acme[['Q1','Q2','Q3','Q4','Q5','Q6']].mean(axis=1)\n",
    "\n",
    "acme['SAT_AVE'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view summary statistics of response variable\n",
    "summary = acme['SAT_AVE'].describe()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Now let's clean up the data.  This will involve handling duplicate data, renaming variables, remapping values of variables, converting data types and creating derived variables to arrive at the dataset to be used in modeling.___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get number of rows\n",
    "acme['RESP_ID'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get number of unique rows\n",
    "acme['RESP_ID'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find duplicate rows\n",
    "duplicateRowsDF = acme[acme.duplicated(['RESP_ID'],keep=False)]\n",
    "\n",
    "#Display rows\n",
    "duplicateRowsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate row\n",
    "acme.drop_duplicates(subset ='RESP_ID', keep = 'first', inplace = True)\n",
    "\n",
    "#Ensure duplicate is removed\n",
    "acme['RESP_ID'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display values counts of 'SCREENER_1'\n",
    "acme['SCREENER_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all NaN values with 0\n",
    "acme['SCREENER_1'] = acme['SCREENER_1'].fillna('0')\n",
    "\n",
    "#Map values to integers\n",
    "acme['CLAIM'] = acme['SCREENER_1'].replace({'No':'0','DK':'0','Yes':'1'}).astype('category')\n",
    "\n",
    "#Display values counts\n",
    "acme['CLAIM'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display values counts of 'SCREENER_3'\n",
    "acme['SCREENER_3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all NaN values with 0\n",
    "acme['SCREENER_3'] = acme['SCREENER_3'].fillna('0')\n",
    "\n",
    "#Map values to integers\n",
    "acme['PREMIUM'] = acme['SCREENER_3'].replace({'No':'0',\"DON'T KNOW\":'0','Yes':'1'}).astype('category')\n",
    "\n",
    "#Display value counts\n",
    "acme['PREMIUM'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display value counts of 'POLICY_TYPE'\n",
    "acme.groupby('POLICY_TYPE').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert 'POLICY_TYPE' to categorical variable\n",
    "acme['POLICY_TYPE'] = acme['POLICY_TYPE'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename 'SCREENER_2' to TENURE\n",
    "acme['TENURE'] = acme['SCREENER_2']\n",
    "\n",
    "#View 'TENURE' summary statistics\n",
    "summary = acme['TENURE'].describe()\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View density plot of 'TENURE'\n",
    "acme['TENURE'].plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take columns 'Q17_1' to 'Q17_8'\n",
    "acme_tp = acme.loc[:, 'Q7_1':'Q7_8']\n",
    "\n",
    "acme_tp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert NaN's to string\n",
    "acme_tp = acme_tp.astype(str)\n",
    "\n",
    "#View all values of 'Q17_1' to 'Q17_8'\n",
    "np.unique(acme_tp.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all NaN values with 0\n",
    "acme['Q7_1'] = acme['Q7_1'].fillna('0')\n",
    "acme['Q7_2'] = acme['Q7_2'].fillna('0')\n",
    "acme['Q7_3'] = acme['Q7_3'].fillna('0')\n",
    "acme['Q7_4'] = acme['Q7_4'].fillna('0')\n",
    "acme['Q7_5'] = acme['Q7_5'].fillna('0')\n",
    "acme['Q7_6'] = acme['Q7_6'].fillna('0')\n",
    "acme['Q7_7'] = acme['Q7_7'].fillna('0')\n",
    "acme['Q7_8'] = acme['Q7_8'].fillna('0')\n",
    "\n",
    "#Map 'Yes' to 1 and all other values to 0\n",
    "map_contact_num = {'No':'0','DK':'0','Yes':'1'}\n",
    "\n",
    "#Apply mapping and convert values to numeric type\n",
    "acme['Q7_1'] = pd.to_numeric(acme['Q7_1'].replace(map_contact_num))\n",
    "acme['Q7_2'] = pd.to_numeric(acme['Q7_2'].replace(map_contact_num))\n",
    "acme['Q7_3'] = pd.to_numeric(acme['Q7_3'].replace(map_contact_num))\n",
    "acme['Q7_4'] = pd.to_numeric(acme['Q7_4'].replace(map_contact_num))\n",
    "acme['Q7_5'] = pd.to_numeric(acme['Q7_5'].replace(map_contact_num))\n",
    "acme['Q7_6'] = pd.to_numeric(acme['Q7_6'].replace(map_contact_num))\n",
    "acme['Q7_7'] = pd.to_numeric(acme['Q7_7'].replace(map_contact_num))\n",
    "acme['Q7_8'] = pd.to_numeric(acme['Q7_8'].replace(map_contact_num))\n",
    "\n",
    "\n",
    "\n",
    "#Calculate the number of times each customer was in contact with an agent about a claim\n",
    "acme['Q7_SUM'] = acme.loc[:,'Q7_1':'Q7_8'].sum(axis=1)\n",
    "\n",
    "#Display value counts \n",
    "acme['Q7_SUM'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acme['Q7_SUM'].hist(bins=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View start/end time\n",
    "acme[['SURVEY_START_TIME','SURVEY_END_TIME']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "#Convert 'SURVEY_START_TIME' and 'SURVEY_START_TIME' to datetimes\n",
    "acme['SURVEY_START_TIME'] = pd.to_datetime(acme['SURVEY_START_TIME'])\n",
    "acme['SURVEY_END_TIME'] = pd.to_datetime(acme['SURVEY_END_TIME'])\n",
    "\n",
    "#Get duration of call\n",
    "acme['SURVEY_DURATION'] = acme['SURVEY_END_TIME']-acme['SURVEY_START_TIME']\n",
    "\n",
    "#Convert to seconds\n",
    "acme['SURVEY_DURATION'] = acme['SURVEY_DURATION'].astype('timedelta64[s]')\n",
    "\n",
    "acme['SURVEY_DURATION'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display value counts of 'GENERATION'\n",
    "acme.groupby('GENERATION').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "#Convert 'GENERATION' to ordered categorical variable\n",
    "acme['GENERATION'] = acme['GENERATION'].astype('category')\n",
    "\n",
    "#Check data type\n",
    "acme['GENERATION'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display value counts of 'REGION'\n",
    "acme.groupby('REGION').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert 'REGION' to ordered categorical variable\n",
    "acme['REGION'] = acme['REGION'].astype('category')\n",
    "\n",
    "#Check data type\n",
    "acme['REGION'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take variables to be used in analysis\n",
    "acme_final_variables = acme[[\"REGION\", \"GENERATION\", \"POLICY_TYPE\", \"TENURE\", \n",
    "                    \"CLAIM\", \"PREMIUM\", \"SURVEY_DURATION\", \"Q7_SUM\", \"SAT_AVE\"]]\n",
    "\n",
    "#look over final dataset\n",
    "acme_final_variables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look over final dataset metadata\n",
    "acme_final_variables.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___We will use one-hot encoding to transform our categorical variables to a form our models will understand.___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummy variables for categorical variables\n",
    "acme_final = pd.get_dummies(acme_final_variables, prefix=['REGION','GENERATION','POLICY_TYPE','PREMIUM','CLAIM'])\n",
    "\n",
    "#Drop reference variables to avoid multicolinearity\n",
    "acme_final = acme_final.drop(['REGION_Mid-Atlantic','GENERATION_Baby Boomers','POLICY_TYPE_Multi-Line','CLAIM_0','PREMIUM_0'],axis='columns')\n",
    "\n",
    "acme_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Finally, we are ready to build and interpret our models.  We will be creating and interpretting a regression model and a random forest model.  We will compare how well they are able to make predictions on a testing set, and the degree of influence each of the predictor variables had on the response___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Create response variable dataframe\n",
    "y = acme_final['SAT_AVE']\n",
    "\n",
    "#Create feature variables dataframe\n",
    "X_1 = acme_final.loc[:, 'TENURE':'Q7_SUM']\n",
    "\n",
    "X_2 = acme_final.loc[:, 'REGION_California':'CLAIM_1']\n",
    "\n",
    "X = pd.concat([X_1,X_2], axis=1)\n",
    "\n",
    "#Split data into training and testing sets (training: 75%, Testing: 25%)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "#Create OLS multiple regressions model\n",
    "reg_model = sm.OLS(endog=train_labels, exog=sm.add_constant(train_features)).fit()\n",
    "reg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Use regression model to predict on testing data\n",
    "reg_preds = reg_model.predict(sm.add_constant(test_features))\n",
    "\n",
    "#Calculate the average squared difference between the estimated values and the actual value\n",
    "MSE = mean_squared_error(y_true = test_labels, y_pred = reg_preds)\n",
    "\n",
    "#Print MSE\n",
    "print('Mean Squared Error:', MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "RFR = RandomForestRegressor(n_estimators = 1500,max_depth=4,random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RFR.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest to predict on test data\n",
    "rf_preds = rf.predict(test_features)\n",
    "\n",
    "#Calculate the average squared difference between the estimated values and the actual value\n",
    "MSE = mean_squared_error(y_true = test_labels, y_pred = rf_preds)\n",
    "\n",
    "#Print MSE\n",
    "print('Mean Squared Error:', MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View features' importances in determining splits\n",
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = train_features.columns,\n",
    "                                    columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
